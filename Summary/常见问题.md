### 线程and进程

1. 信号的生命周期？  
    信号产生-》信号在进程中注册-》信号在进程中的注销-》执行信号处理函数 

2. 信号的产生方式？  
   + 当用户按某些终端键时产生信号 
   + 硬件异常产生信号【内存非法访问】 
   + 软件异常产生信号【某一个条件达到时】 
   + 调用kill函数产生信号【接受和发送的所有者必须相同，或者发送的进程所有者必须为超级用户
   + 运行kill命令产生信号  

3. 信号处理方式？  
   + 执行默认处理方式  
   + 忽略处理  
   + 执行用户自定义的函数  

4. linux内部提供了那些调试宏？
   + __FILE__：表示在哪个文件  
   + __LINE__：表示在当前多少行  
   + __FUNCTION__：表示在执行在哪个函数  

5. 死锁的原因？条件？如何预防？又如何避免？如何解除？

   1. 资源不能共享，只能由一个进程使用。
   2. 请求与保持（Hold andwait）：已经得到资源的进程可以再次申请新的资源。
   3. 不可剥夺（Nopre-emption）：已经分配的资源不能从相应的进程中被强制地剥夺。
   4. 循环等待：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源

   + 处理死锁的策略： 
     + 忽略该问题。例如鸵鸟算法，该算法可以应用在极少发生死锁的的情况下。为什么叫鸵鸟算法呢，因为传说中鸵鸟看到危险就把头埋在地底下，可能鸵鸟觉得看不到危险也就没危险了吧。跟掩耳盗铃有点像。
     + 检测死锁并且恢复。
     + 仔细地对资源进行动态分配，以避免死锁。
     + 通过破除死锁四个必要条件之一，来防止死锁产生。  

6. 解决hash冲突的方法？
    线性探测法；开链法；再哈希法；  

7. 进程与线程的区别？
对于有线程系统： 
* 进程是资源分配的独立单位
* 线程是资源调度的独立单位

对于无线程系统：
* 进程是资源调度、分配的独立单位

##### 进程之间的通信方式以及优缺点

  * 管道（PIPE）
      * 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信
          * 优点：可以实现任意关系的进程间的通信
          * 缺点：
              1. 长期存于系统中，使用不当容易出错
              2. 缓冲区有限
      * 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程）
          * 优点：简单方便
          * 缺点：
              1. 局限于单向通信 
              2. 只能创建在它的进程以及其有亲缘关系的进程之间
              3. 缓冲区有限
  * 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问
      * 优点：可以同步进程
      * 缺点：信号量有限
  * 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个事件已经发生
  * 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识
      * 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
      * 缺点：信息的复制需要额外消耗 CPU 的时间，不适宜于信息量大或操作频繁的场合
  * 共享内存（Shared Memory）：映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问
      * 优点：无须复制，快捷，信息量大
      * 缺点：
          1. 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
          2. 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信
  * 套接字（Socket）：可用于不同及其间的进程通信
      * 优点：
          1. 传输数据为字节级，传输数据可自定义，数据量小效率高
        2. 传输数据时间短，性能高
        3. 适合于客户端和服务器端之间信息实时交互
        4. 可以加密,数据安全性强
    * 缺点：需对传输的数据进行解析，转化成应用级的数据。

##### 线程之间的通信方式

  * 锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）
      * 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
      * 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。
      * 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持着是否已经释放锁。
      * 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
  * 信号量机制(Semaphore)
      * 无名线程信号量
      * 命名线程信号量
  * 信号机制(Signal)：类似进程间的信号处理
  * 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制  

> 进程之间的通信方式以及优缺点：[进程线程面试题总结](http://blog.csdn.net/wujiafei_njgcxy/article/details/77098977)

##### 进程之间私有和共享的资源
  * 私有：地址空间、堆、全局变量、栈、寄存器
  * 共享：代码段，公共数据，进程目录，进程 ID

##### 线程之间私有和共享的资源
  * 私有：线程栈，寄存器，程序寄存器
  * 共享：堆，地址空间，全局变量，静态变量

8.  什么是守护进程？如何查看守护进程？什么是僵尸进程？如何查看僵尸进程？
    + 守护进程：一个生命周期长，并且控制终端，然后周期性执行某种任务的进程  
    + 查看守护进程：ps a  
    + 僵尸进程：进程退出，但是占用资源没有被回收  
    + 查看僵尸进程：ps -ef|grep defunct  

9.  进程同步机制？
    进程间通信机制中唯一的异步通信机制  

10. 什么是信号？
    一种比较复杂的通信方式，用于通知接收进程某个事件已经发生  

11. kill函数的每一个参数的作用？
    Pid>0：发给ID为pid的进程  
    Pid=0：发给进程组所有的进程  
    Pid=-1：发给所有的进程  
    Pid<-1：发给指定进程组的进程  

    这个 kill 命令不是真的“杀死”程序，而是给程序 发送信号。信号是操作系统与程序之间进行通信时所采用的几种方式中的一种。 在使用 Ctrl-c 和 Ctrl-z 的过程中我们已经看到信号的实际用法。当终端接受了其中一个按键组合后，它会给在前端运行 的程序发送一个信号。在使用 Ctrl-c 的情况下，会发送一个叫做 INT（Interrupt,中断）的信号；当使用 Ctrl-z 时，则发送一个叫做 TSTP（Terminal Stop,终端停止）的信号。程序，相应地，监听信号的到来，当程序 接到信号之后，则做出响应。一个程序能够监听和响应信号这件事允许一个程序做些事情， 比如，当程序接到一个终止信号时，它可以保存所做的工作。
    > [“杀死”程序](https://www.cnblogs.com/whutao/p/10478946.html)

12. 虚拟内存实现有哪几种方式？有什么意义？
    三种：请求分页存储管理；请求分段存储管理；请求段页式存储管理 

13. 什么是类型安全？能举例吗？
    两个类型直接进行转换，必须是显式的，string和STL模板是类型安全的 

14. 确保线程安全的几种方式？
    + 原子操作
    + 同步与锁
    + 可重入
    + 阻止过度优化volatile

15. Pthread_cond_signal和pthread_cond_broadcast的区别
    + Pthread_cond_signal表示唤醒睡眠线程中的一个【单播，可能按照优先级或者先来后到的原则】  
    + Pthread_cond_boardcast表示唤醒所有睡眠线程【广播】  

16. 线程同步几种方式？  
17. 线程池的作用是什么？  
    处理线程多并发，用一个数组保存线程，然后一直放着，如果没用就用条件变量让它休眠，如果加入一个新的任务就唤醒其中一个去执行这个任务。  

18. 用户态和内核态的切换
    因为操作系统的资源是有限的，如果访问资源的操作过多，必然会消耗过多的资源，而且如果不对这些操作加以区分，很可能造成资源访问的冲突。  
    所以，为了减少有限资源的访问和使用冲突，Unix/Linux的设计哲学之一就是：对不同的操作赋予不同的执行等级，就是所谓特权的概念。简单说就是有多大能力做多大的事，与系统相关的一些特别关键的操作必须由最高特权的程序来完成。  
    Intel的X86架构的CPU提供了0到3四个特权级，数字越小，特权越高，**Linux操作系统中主要采用了0和3两个特权级，分别对应的就是内核态和用户态。**   
    运行于用户态的进程可以执行的操作和访问的资源都会受到极大的限制，而运行在内核态的进程则可以执行任何操作并且在资源的使用上没有限制。很多程序开始时运行于用户态，但在执行的过程中，一些操作需要在内核权限下才能执行，这就涉及到一个从用户态切换到内核态的过程。比如C函数库中的内存分配函数malloc()，它具体是使用sbrk()系统调用来分配内存，当malloc调用sbrk()的时候就涉及一次从用户态到内核态的切换，类似的函数还有printf()，调用的是wirte()系统调用来输出字符串，等等。  

    到底在什么情况下会发生从用户态到内核态的切换，一般存在以下三种情况：

    + 当然就是系统调用：原因如上的分析。
    + 异常事件： 当CPU正在执行运行在用户态的程序时，突然发生某些预先不可知的异常事件，这个时候就会触发从当前用户态执行的进程转向内核态执行相关的异常事件，典型的如缺页异常。
    + 外围设备的中断：当外围设备完成用户的请求操作后，会像CPU发出中断信号，此时，CPU就会暂停执行下一条即将要执行的指令，转而去执行中断信号对应的处理程序，如果先前执行的指令是在用户态下，则自然就发生从用户态到内核态的转换。

### C++基本知识
1. 如何消除隐式转换？

[Explicit](https://www.cnblogs.com/bastard/archive/2012/02/09/2344425.html)

2. 重载，重写和隐藏的区别？
   + 函数重载：函数重载必须在同一个类中进行；子类无法重载父类函数，父类同名函数将被名称覆盖；重载是在编译器期间根据参数类型和个数决定函数调用(静态联编)。   
   + 函数重写：函数重写必须发生在父类与子类之间；父类与子类的函数原型完全一样；使用virtual声明之后能够产生多态(如果不写virtual关键字，称为重定义)；  
   + 多态是在运行期间根据具体对象的类型来决定函数调用  

3. volatile表示什么？有什么作用？
   + Volatile关键词的第一个特性：易变性。所谓的易变性，在汇编层面反映出来，就是两条语句，下一条语句不会直接使用上一条语句对应的volatile变量的寄存器内容，而是重新从内存中读取。  
   + Volatile关键词的第二个特性：“不可优化”特性。volatile告诉编译器，不要对我这个变量进行各种激进的优化，甚至将变量直接消除，保证程序员写在代码中的指令，一定会被执行。  
   + Volatile关键词的第三个特性：“顺序性”，能够保证Volatile变量间的顺序性，编译器不会进行乱序优化。  
   + C/C++ Volatile变量，与非Volatile变量之间的操作，是可能被编译器交换顺序的。C/C++ Volatile变量间的操作，是不会被编译器交换顺序的。哪怕将所有的变量全部都声明为volatile，哪怕杜绝了编译器的乱序优化，但是针对生成的汇编代码，CPU有可能仍旧会乱序执行指令，导致程序依赖的逻辑出错，volatile对此无能为力，针对这个多线程的应用，真正正确的做法，是构建一个happens-before语义。  

4. Static_cast<>,dynamic_cast<>,const_cast<>,reinterpret_cast<>的各自作用和使用环境？


5. malloc和new的区别？
   + new需要调用构造函数，malloc只是申请一块内存。  
   + new不需要指定内存，malloc需要指定内存  
   + new出来的类型固定，malloc出来的是void*  
   + malloc出来的是在堆上内存，new出来的是自由存储区  
   + new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时返回NULL。**所以对申请情况的判断也不一样**  
   + 对于非内部数据类型的对象而言，光用malloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。  

6. free和delete的区别？
    delete调用析构函数，然后调用free。free直接释放

7. free一个数组时如何知道要释放多大的内存呢？
    + malloc是C/C++中的动态内存分配的标准库函数，函数原型：void* malloc(unsigned int size)；其功能就是在堆上动态开辟内存空间，它的特点：  
   
      + 返回值为void*，（void* 类型可以强制转换为任何其它类型的指针，但反过来就不行了）；  
      + 需要具体指定要分配空间的大小size，且size类型为无符整型（unsigned int）；  
      + 它允许申请0个长度的内存（这点很有意思吧）；  
      + 其申请到的空间逻辑上是连续的，物理上是离散的（链表形式管理）。  

    在malloc分配了空间后，free释放空间的时候是怎么知道要free的空间的大小呢？  

    + 其实真正的内存管理如申请/释放等，并不是由malloc或者free等库函数来负责的，而是交由操作系统去完成，**它们只是维护一个空闲的链表式的内存块，理解这一点是问题的关键**。例如：要申请sizeof(int) x 100大小的内存空间，虽然返回的是内存大小是400，但实际上，**操作系统分配时候，会多出一块用于存储内存大小的类似链表head头节点的东西，这个节点存储的是空间的首地址及分配内存的大小。当用户调用free函数的时候，其实它也不知道要释放内存的大小，它只需改变head头结点里的内存的大小就可以了，具体内存空间的释放由操作系统去完成**。  

8. __stdcall和__cdecl的区别？
    + 采用__cdecl约定时，函数参数按照从右到左的顺序入栈，并且由调用函数者把参数弹出栈以清理堆栈。因此，实现可变参数的函数只能使用该调用约定。由于每一个使用__cdecl约定的函数都要包含清理堆栈的代码，所以产生的可执行文件大小会比较大。
    + 采用__stdcall约定时，函数参数按照从右到左的顺序入栈，被调用的函数在返回前清理传送参数的栈，函数参数个数固定。由于函数体本身知道传进来的参数个数，因此被调用的函数可以在返回前用一条ret n指令直接清理传递参数的堆栈。

9. 引用和指针的区别？
    + 指针可以为空，引用不能为空。
    + 引用不能改变引用对象，至死不渝，但是能改变引用的值；指针可以随便乱指。
    + 引用的大小是引用对象的大小；指针大小就是4或者8。

10. 出现异常时，try和catch做了什么？
    + 搜不到

11. C++如何处理多个异常的？
    + 搜不到

12. 常对象的成员变量一定不可以修改吗？为什么？
    + 常对象中所有的成员变量的值都不能被修改
    + 常对象访问函数时只能访问常成员函数；

13. 虚函数的调用过程？
    13.1 编译器在什么地方动了手脚，从而支持了多态？  
    真正确定绑定关系的地方，就是创建对象的时候！！这时候C++编译器会偷偷的给对象添加一个vptr指针。  
    在发生多态的地方，编译器根本不会去区分传进来的是子类对象还是父类对象。而是关心print()是否为虚函数，如果是虚函数，就根据不同对象的vptr指针找属于自己的函数。而且父类对象和子类对象都会有vptr指针，传入对象不同，编译器会根据vptr指针，到属于自己虚函数表中找自己的函数。即：vptr--->虚函数表------>函数的入口地址，从而实现了迟绑定(在运行的时候，才会去判断)。  

    如果不是虚函数，那么这种绑定关系在编译的时候就已经确定的，也就是**静态联编**！
  
    13.2 多态的实现原理  
    + 说明1：通过虚函数表指针VPTR调用重写函数是在程序运行时进行的，因此需要通过寻址操作才能确定真正应该调用的函数。而普通成员函数是在编译时就确定了调用的函数。在效率上，虚函数的效率要低很多。  
    + 说明2：出于效率考虑，没有必要将所有成员函数都声明为虚函数  
    + 说明3：C++编译器，执行play函数，不需要区分是子类对象还是父类对象  
  
14. 单继承，多继承，菱形继承，虚继承时，对象内存中的差异区别？如果存在虚函数呢？
    虚继承内存多一个虚函数指针，指向虚函数表。

15. C++分为内存分为哪几部分？
    在c++中，共有五种内存。**栈、堆、自由存储区、全局/静态存储区、常量存储区**。  
    栈中：存储一些局部变量，在作用区域结束后，被程序释放掉。  
    堆中：存储一些new出来的变量，自己new，自己delete。  
    自由存储区：malloc出来的，自己free。  
    全局/静态存储区，常量存储区  

    15.1 堆内存和栈内存的区别  
    + 栈内存由系统分配，系统负责管理，堆内存由开发者进行管理，容易发生内存泄漏  
    + 空间大小不同，堆内存一般可以达到4G（32系统），栈内存一般较小（可以修改）  
    + 碎片问题，堆内存频繁的new/delete会影响程序的效率，栈内存则不会，清空操作的时候，后进先出，已经清理完毕了。  
    + 生长方向，堆内存是向着地址逐渐增大的方向，栈内存是向着地址逐渐变小的方向。  
    + 分配效率，栈内存由计算机系统底层进行指令支持，效率要高一些；堆内存有c++函数库进行支持，按照大小进行空间搜索进行分配，如果没有足够大的空间，则向系统申请空间。  

    15.2 常见内存错误  
    + 内存没有申请成功，却使用了他  
    + 内存申请成功，却没有初始化。  
    + 内存越界。  
    + 忘记释放内存，或者释放内存后继续使用。

16. 如果new申请内存失败了，如何去解决？如果让你实现一个new，你会怎么实现？
    + 对于new出来的对象指针来说，其实，if ( p == 0 ) 完全是没啥意义的。C++ 里，如果 new 分配内存失败，默认是抛出异常的。所以，如果分配成功，p == 0 就绝对不会成立；
    + 而如果分配失败了，也不会执行 if ( p == 0 )，**因为分配失败时，new 就会抛出异常跳过后面的代码。如果你想检查 new 是否成功，应该捕捉异常**。  

+ malloc 的写法  
  ```
  char* buffer = (char*)malloc(1024); 
  if(buffer)
  {
      printf("malloc success!\r\n"); 
  }
  free(buffer);
  ```

+ new的写法  
  ```
  try
   { 
       char* buffer = new char[1024]; 
   } 
   catch(...)
   { 
       printf("operator new error!\r\n"); 
   } 
   delete []buffer;
  ```


17. 如何得到一个结构体内成员的偏移量？
    
18. 为什么要字节对齐？
    现代计算机中内存空间都是按照byte划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但是实际情况上，在访问特定类型变量的时候经常在特定的内存地址访问，这就是需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐。  
    平台的原因：不是所有的平台都是任意的访问数据的，某些硬件平台只能在某些地址处取某些数据 ，否则抛异常。  
    性能的原因：数据结构应该尽可能地在自然边界上对齐，原因在于为了访问未对齐的内存，处理器需要做两次访问内存，而对齐的内存访问只需要一次访问。  

19. 在成员函数中调用delete this会出现什么问题？对象还可以使用吗？
    + delete this之后，不能再使用this访问对象及成员变量及虚函数。delete this回收的是数据，这包括对象的数据成员以及vtable，不包括函数代码  
    + this对象是必须是用 new操作符分配的（而不是用new[]，也不是用placement new，也不是局部对象，也不是global对象）；  

20. 如果在构造函数中调用memset(this, 0, sizeof(*this))来初始化内存空间，有什么问题吗？
    + 如果基类A存在虚函数，类B是这个基类的子类，在类B的构造函数体内仅仅调用memset(this,0,sizeof(*this));那么此操作会将虚表指针的值置为0，则无法索引到虚函数表，因此无法使用虚函数机制，即指向子类对象的基类指针或引用调用虚函数，在程序运行期间此时无法确定调用虚函数的版本。

21. 对一个数组而言，delete a和delete[] a有什么区别？为什么？
    + 针对简单类型 使用new分配后的不管是数组还是非数组形式内存空间用两种方式均可.
        ```
        int *a = new int[10];
        delete a;
        delete [] a;
        ```
    此种情况中的释放效果**相同**，原因在于：分配简单类型内存时，内存大小已经确定，系统可以记忆并且进行管理，在析构时，系统并不会调用析构函数，它直接通过指针可以获取实际分配的内存空间，哪怕是一个数组内存空间(在分配过程中 系统会记录分配内存的大小等信息，此信息保存在结构体_CrtMemBlockHeader中)  
    + 针对类Class，两种方式体现出具体差异
        ```
        class A{};
        A *a = new A[10];
        delete a;
        delete[] a;
        ```
   
      + delete a; 仅释放了a指针指向的全部内存空间，但是只调用了a[0]对象的析构函数，剩下的从a[1]到a[9]这9个用户自行分配的m_cBuffer对应内存空间将不能释放，从而造成内存泄漏  
      + delete [] a; 调用使用类对象的析构函数释放用户自己分配内存空间并且释放了a指针指向的全部内存空间  

22. Dynamic_cast是如何实现运行时类型转换的？


23. C语言调用C++语法函数怎么做？那C++调用C语法的函数怎么做？
    + extern “C”

24. Extern “C”是什么意思？他有什么作用？
    在C语言中，修饰符extern用在变量或者函数的声明前，用来说明**此变量/函数是在别处定义的，要在此处引用**。  

    注意extern声明的位置对其作用域也有关系，如果是在main函数中进行声明的，则只能在main函数中调用，在其它函数中不能调用。其实要调用其它文件中的函数和变量，只需把该文件用#include包含进来即可，为啥要用extern？**因为用extern会加速程序的编译过程，这样能节省时间**。  

    在C++中extern还有另外一种作用，用于指示C或者C＋＋函数的调用规范。比如在C＋＋中调用C库函数，就需要在C＋＋程序中用extern “C”声明要引用的函数。这是给链接器用的，**告诉链接器在链接的时候用C函数规范来链接**。主要原因是C＋＋和C程序编译完成后在目标代码中命名规则不同，用此来解决名字匹配的问题。  

25. 静态函数能定义为虚函数吗？为什么？
    + **static成员不属于任何类对象或类实例**，所以即使给此函数加上virutal也是没有任何意义的。
    + 静态与非静态成员函数之间有一个主要的区别。那就是**静态成员函数没有this指针**。

26. 对于默认处理的结构体，能用memcmp来进行比较吗？为什么？如果不能，该如何比较？
    可以通过memcmp()来比较2个相同的结构体变量，但这2个变量必须在赋值前进行清零初始化（否则结果不准确） ，或者2者是通过直接对等赋值而来。  

27. Struct{char a[0];}的作用？有什么好处？


28. 如何判断两个浮点数相等？
    用"=="来比较两个double应该相等的类型，返回真值完全是不确定的。计算机对浮点数的进行计算的原理是只保证必要精度内正确即可。  
    我们在判断浮点数相等时，推荐用范围来确定，若x在某一范围内，我们就认为相等，至于范围怎么定义，要看实际情况而已了，float,和double 各有不同  
    所以  
    const float EPSINON = 0.00001;  
    if((x >= - EPSINON) && (x <= EPSINON)  
    这样判断是可取的至于为什么取0.00001，可以自己按实际情况定义。  
    ```
    const foat EPSINON = 0.000001;
    float A = 80.43323,B = 80.433199;
    float x = A - B;
    if ((x >= - EPSINON)&& (x <= EPSINON)
        cout<<"A 与B相等"<<endl;
    else
        cout<<"不相等"<<endl;
    ```

29. 变量的存储方式有哪些？
    + 变量可以分为全局变量、静态全局变量、静态局部变量和局部变量
    + 按存储区域分：全局变量、静态全局变量和静态局部变量都存放在内存的全局数据区，局部变量存放在内存的栈区
    + 按作用域分：全局变量在整个工程文件内都有效；静态全局变量只在定义它的文件内有效；静态局部变量只在定义它的函数内有效，只是程序仅分配一次内存，函数返回后，该变量不会消失；局部变量在定义它的函数内有效，但是函数返回后失效。
    + 全局变量和静态变量如果没有手工初始化，则由编译器初始化为0。**局部变量的值不可知**。  

30. 虚函数表是在什么时候确定的？那虚表指针呢？
    构造函数调用的时候创建虚表指针；编译的时候创建虚函数表。

31. C++中有哪些机制可以取代宏？
    内联函数、const等

32. 系统调用与函数调用的区别？

33. this指针调用成员变量时，堆栈会发生什么变化？
    将相应的参数从右往左压栈，然后将this指针放到寄存器中  

34. C++中可以继承string类吗？为什么？
    不可以。因为string是模板，不是类  

35. Char * const *(*next)()是什么？
    next是一个指针，指向一个函数，这个函数返回一个指针，这个指针指向char类型的常量指针  

36. 如何判断const所修饰的对象？
    const只修饰其后的【变量】，至于const放在类型前还是类型后并没有区别

37. 构造函数能不能虚函数？为什么？那拷贝构造函数能不能为虚函数？为什么？
    从存储空间角度，虚函数对应一个指向vtable虚函数表的指针，这大家都知道，可是这个指向vtable的指针其实是存储在对象的内存空间的。问题出来了，如果构造函数是虚的，就需要通过 vtable来调用，可是对象还没有实例化，也就是内存空间还没有，怎么找vtable呢？所以构造函数不能是虚函数。  
    **其实可以利用虚函数的机制来实现上述功能**!正儿八经的来说，还是不允许构造函数或者拷贝构造函数声明为虚函数的。  
    [论虚构造函数与虚复制构造函数的实现](https://blog.csdn.net/dicky3651/article/details/5421662)  
    下文来自<< more effective c++ >>:
    > 正如我们看到的，类的虚拟拷贝构造函数只是调用它们真正的拷贝构造函数。因此“拷贝”的含义与真正的拷贝构造函数相同。
    > 如果真正的拷贝构造函数只做了简单的拷贝，那么虚拟拷贝构造函数也做简单的拷贝。
    > 如果真正的拷贝构造函数做了全面的拷贝，那么虚拟拷贝构造函数也做全面的拷贝。
    > 如果真正的拷贝构造函数做一些奇特的事情，象引用计数或copy-on-write（参见条款 M29），那么虚拟构造函数也这么做。
    > 完全一致，太棒了。

    上述讨论的机制是如何将一个函数虚拟化，即：
    > 具有虚拟行为的非成员函数很简单。**你编写一个虚拟函数来完成工作，然后再写一个非虚拟函数，它什么也不做只是调用这个虚拟函数**。
    > 为了避免这个句法花招引起函数调用开销，你当然可以内联这个非虚拟函数（参见 Effective C++ 条款 33）。

```
class A
{
public:
    A(int);
    A(A const &rhs);
    virtual ~A();
    virtual A* clone()
    {  
        return  new A (*this);
    }
};

class B:public A
{
public:
    B(int);
    B(B const &rhs);
    virtual ~B();
    virtual B* clone()
    {
        //return new B();    //调用构造函数；
        return new B(*this); //调用拷贝构造函数；
    }
};
```

38. 析构函数能不能虚函数？为什么？
    在实现多态时，当用基类操作派生类，在析构时防止只析构基类而不析构派生类的状况发生。  
    如果不需要基类对派生类及对象进行操作,则不能定义虚函数,因为这样会增加内存开销.当类里面有定义虚函数的时候,编译器会给类添加一个虚函数表,里面来存放虚函数指针,这样就会增加类的存储空间.所以,只有当一个类被用来作为基类的时候,才把析构函数写成虚函数.  

39. 模板和实现可不可以不写在一个文件里面？为什么？
    分开写。只能写在一个一个的头文件中。原因：多文件处理变为一个文件其实是通过链接器来实现的，所以如果用源文件来处理模板实现，会导致链接失效，最主要的原因还是在编译，编译器会暂时不处理模板类只有在实例化对象时才去处理，但是这就需要实现的代码了，如果放在其他文件的话，就会无法形成相应的类。  

40. 什么是RAII资源管理？
    即资源获取就是初始化，利用对象生命周期来控制程序资源，简单来说就是通过局部对象来处理一些资源问题  

41. 如何检查内存泄露？如果不通过printf,debug等调试方式和编译器报错提示呢？
    使用GDB调试器  

42. Int(*f(int,void(*)()))(int,int)是什么意思？
    一个函数，参数为int和指向返回值为void的无参数的函数指针，返回值为一个指向返回值为int，参数为int和int的函数指针  

### STL

#### STL提供六大组件，彼此可以组合套用：

1. 容器（Containers）：各种数据结构，如：序列式容器vector、list、deque、关联式容器set、map、multiset、multimap。用来存放数据。从实现的角度来看，STL容器是一种class template。  

2. 算法（algorithms）：各种常用算法，如：sort、search、copy、erase。从实现的角度来看，STL算法是一种 function template。注意一个问题：任何的一个STL算法，都需要获得由一对迭代器所标示的区间，用来表示操作范围。这一对迭代器所标示的区间都是前闭后开区间，例如[first, last)  

3. 迭代器（iterators）：容器与算法之间的胶合剂，是所谓的“泛型指针”。共有五种类型，以及其他衍生变化。从实现的角度来看，迭代器是一种将 operator*、operator->、operator++、operator-- 等指针相关操作进行重载的class template。所有STL容器都有自己专属的迭代器，只有容器本身才知道如何遍历自己的元素。原生指针(native pointer)也是一种迭代器。  

4. 仿函数（functors）：行为类似函数，可作为算法的某种策略（policy）。从实现的角度来看，仿函数是一种重载了operator（）的class或class template。一般的函数指针也可视为狭义的仿函数。  

5. 配接器（adapters）：一种用来修饰容器、仿函数、迭代器接口的东西。例如：STL提供的queue 和 stack，虽然看似容器，但其实只能算是一种容器配接器，因为它们的底部完全借助deque，所有操作都由底层的deque供应。改变 functors接口者，称为function adapter；改变 container 接口者，称为container adapter；改变iterator接口者，称为iterator adapter。  

6. 配置器（allocators）：负责空间配置与管理。从实现的角度来看，配置器是一个实现了动态空间配置、空间管理、空间释放的class template。  

+ 总结：这六大组件的交互关系：container（容器） 通过 allocator（配置器） 取得数据储存空间，algorithm（算法）通过 iterator（迭代器）存取 container（容器） 内容，functor（仿函数） 可以协助 algorithm（算法） 完成不同的策略变化，adapter（配接器） 可以修饰或套接 functor（仿函数）  

##### 序列式容器

+ vector-数组，元素不够时再重新分配内存，拷贝原来数组的元素到新分配的数组中.  
+ list-单链表。  
+ deque-分配中央控制器map(并非map容器)，map记录着一系列的固定长度的数组的地址.记住这个map仅仅保存的是数组的地址,真正的数据在数组中存放着.deque先从map中央的位置(因为双向队列，前后都可以插入元素)找到一个数组地址，向该数组中放入数据，数组不够时继续在map中找空闲的数组来存数据。当map也不够时重新分配内存当作新的map,把原来map中的内容copy的新map中。所以使用deque的复杂度要大于vector，尽量使用vector。  
+ stack-基于deque。  
+ queue-基于deque。  
+ heap-完全二叉树，使用最大堆排序，以数组(vector)的形式存放。  
+ priority_queue-基于heap。  
+ slist-双向链表。  

##### 关联式容器

+ set,map,multiset,multimap-基于红黑树(RB-tree)，一种加上了额外平衡条件的二叉搜索树。

+ hash table-散列表。将待存数据的key经过映射函数变成一个数组(一般是vector)的索引，例如：数据的key%数组的大小＝数组的索引(一般文本通过算法也可以转换为数字)，然后将数据当作此索引的数组元素。有些数据的key经过算法的转换可能是同一个数组的索引值(碰撞问题，可以用线性探测，二次探测来解决)，STL是用开链的方法来解决的，每一个数组的元素维护一个list，他把相同索引值的数据存入一个list，这样当list比较短时执行删除，插入，搜索等算法比较快。  

+ hash_map,hash_set,hash_multiset,hash_multimap-基于hashtable。

 [STL六大组件] (http://blog.csdn.net/chenguolinblog/article/details/30336805)  

#### list和vector有什么区别？

+ vector拥有一段**连续**的内存空间，因此支持随机存取，如果需要高效的随即存取，而不在乎插入和删除的效率，使用vector。  
+ list  拥有一段**不连续**的内存空间，因此不支持随机存取，如果需要大量的插入和删除，而不关心随即存取，则应使用list。  

#### vector增长模式

+ size()函数返回的是已用空间大小，capacity()返回的是总空间大小，capacity()-size()则是剩余的可用空间大小。当size()和capacity()相等，说明vector目前的空间已被用完，如果再添加新元素，则会引起vector空间的动态增长。reserve(n)预先分配一块较大的指定大小的内存空间，其中n为分配空间大小；resize()成员函数只改变元素的数目，不改变vector的容量。  
+ 在VS2010的编译器里面每次并不是增长固定的内存，可以看出是增长当前内存的一半。而且由于我们的程序没有调用reserve（n）函数预先分配一块内存，所以内存增长是编译器自动完成的。这个自动增长包括重新**分配内存空间、拷贝原空间、释放原空间**三个过程，具体策略为当添加元素时，如果vector空间大小不足，则会以原大小的**1.5倍**另外配置一块较大的新空间，然后将原空间内容拷贝过来，在新空间的内容末尾添加元素，并释放原空间。也就是说vector的空间动态增加大小，并不是在原空间之后的相邻地址增加新空间，因为vector的空间是线性连续分配的，不能保证原空间之后有可供配置的空间。这就解释了上述程序的运行结果。  
+ 但是，针对以上自动完成的内存增长过程，由于包括重新分配内存空间、拷贝原空间、释放原空间等步骤，这些过程会降低程序效率，因此可以使用reserve(n)预先分配一块较大的指定大小的内存空间，这样当指定大小的内存空间未使用完时，是不会重新分配内存空间的，这样便提升了效率。  

#### 各种容器之间的区别

+ vector：像数组一样，快速访问任何一个随机的元素，快速的再末尾插入元素，但是在序列中间插入以及删除要素比较慢，一开始分配的空间如果太小的话，重新分配，则拷贝的性能开销很大。  
+ deque：连续的内存区域，支持高效的首部插入和删除元素。  
+ list：非连续的内存区域，插入和删除效率高，随机访问支持不好。  
+ vector和数组之间的关系：数组的维度必须是常量表达式，初始化的时候必须给出。数组不允许拷贝和赋值，即不能将数组的内容拷贝到其他数组作为其初始值，但是vector可以。数组使用的过程容易产生数组越界，而相对于vector则可以使用较多的机制来控制，例如使用迭代器。  

1. 实现一个vector？是1.5还是2倍，各有什么优缺点？
    + 1.5倍优势：可以重用之前分配但是释放的内存;
    + 2倍劣势：每次申请的内存都不可以重用  

2. map底层用了什么？
    红黑树

3. 如果用map删除了一个元素，迭代器还能用吗？为什么？怎样做可以接着用？
    不能，自动指向下一个元素。list也是这样的。  
    应该iter = map.erase(iter);  

4. STL空间配置器如何处理内存的？能说一下它的大概实现方案吗？为什么是8bytes的倍数？
    分为两部分：大于128bytes用*malloc*直接申请，小于128bytes则使用*一个8bytes倍数的数组*来进行申请。  
    为8bytes的原因是为了提高效率，同时对于64位的机器而言，地址大小为8bytes  

### 数据结构

1. 红黑树的特征是什么？
2. 红黑树如何插入和删除的？
3. 红黑树和B+,B-的区别？


### 算法

1. 手写strcpy,memcpy,memmove函数？  

    ```
    void* mymemcpy(void* dst, const void* src,size_t size)
    {
        
        if(src==NULL || dst==NULL) return NULL;
        void* ret = dst;
        while(size--)
        {
            *(char*)dst = *(char*)src;
            dst = (char*)dst + 1;
            src = (char*)src + 1;
        }
        return ret;
    }

    void* mymemmove(void* dst, const void* src,size_t size)
    {
        if(src==NULL || dst==NULL) return NULL;
        char* psrc;
        char* pdst;
        //存在覆盖，自后向前进行拷贝
        if((src<dst) && (char*)src+size > (char*)dst)
        {
            psrc = (char*)src + size-1;
            pdst = (char*)dst + size-1;
            while(size--)
                *pdst-- = *psrc--;
        }
        else
        {
            psrc = (char*)src;
            pdst = (char*)dst;
            while(size--)
            {
                *pdst++ = *psrc++;
            }
        }
    }

    char *mystrcat(char *dest,const char *src)
    {
        char* temp = dest;
        while(*dest != '\0')
        {
            dest++;
        }

        while((*dest++ = *src++) != '\0');

        return temp;
    }
    char *mystrncat(char *dest,const char *src,size_t n)
    {
        
        char* temp = dest;
        while(*dest != '\0')
        {
            dest++;
        }

        while(n-->0 && (*dest++ = *src++) != '\0');

        return temp;
    }

    void* mymemset(void *s, int c, size_t n )
    {
        unsigned char uc = c;
        unsigned char *su = (unsigned char*)s;
        while(n-->0)
        {
            *su = uc;
            su++;
        }
    }

    int mystrlen(const char* str)
    {
        return *str?(mystrlen(++str)+1):0;
        /*
        const char* eos = str;
        while(*eos++);
        return (eos-str-1);
        */
    }

    int mymemcmp(const void * ptr1, const void * ptr2, size_t num)
    {
        if(ptr1==NULL || ptr2==NULL || num<0) return 0;

        char* pch1 = (char*)ptr1;
        char* pch2 = (char*)ptr2;

        while(num-- && *pch1++ == *pch2++);
        return (pch1-pch2)<<8;
    }

    int mystrcmp ( const char * str1, const char * str2 )
    {
        if(str1==NULL || str2 ==NULL) return 0;

        while(*str1 == *str2)
        {
            str1++;
            str2++;
        }

        return (*str1-*str2);
    }

    int mystrncmp( const char * str1, const char * str2, size_t num )
    {

        if(str1==NULL || str2 ==NULL) return 0;

        while(num-- && *str1 == *str2)
        {
            str1++;
            str2++;
        }

        return (*str1-*str2);
    }

    ```

2. Do{}while(0)的用法有哪些？
   + 可以将语句当做一个独立的域
   + 对于多语句可以正常的运行
   + 可以有效的消除goto语句，达到跳转语句的效果  

3. 手写快排？时间复杂度？空间复杂度？能进行优化吗？还有吗？能进行尾递归优化吗？


4. 逐层打印二叉树？


5. 排序稳定的算法，你知道那些？
    冒泡排序；插入排序；归并排序；基数排序  

6. 手写线程安全的单例模式？

```
class Singleton
{
private: 
static mutex m_mtx;
static Singleton *m_pInstance;
Singleton(){}
~Singleton(){}
public:
static Singleton* getInstance()
{
    if(nullptr == m_pInstance)
    {
        m_mtx.lock();
        if (nullptr == m_pInstance)
        {
            m_pInstance = new Singleton;
        }
    }
}
};
mutex Singleton::m_mtx = NULL;
Singleton Singleton::m_pInstance = NULL;
```

7. 实现一个shared_ptr类和auto_ptr类


8. 手写一个有可变参数的函数？
    使用va_list，va_start，va_arg，va_end。  
    也可以用宏定义##__VA_ARGS__，可以针对空参数消除逗号  

9. string类的构造，析构，拷贝函数

    ```
    class String
    {
    public:
            String(const char *str=NULL); //构造函数
            String(const String &other); //拷贝构造函数
            ~String(void); //析构函数
            String& operator=(const String &other); //等号操作符重载
            ShowString();
    private:
            char *m_data; //指针
    };

    String::~String()
    {
        delete [] m_data; //析构函数，释放地址空间
    }
    String::String(const char *str)
    {
        if (str==NULL)//当初始化串不存在的时候，为m_data申请一个空间存放'\0'；
        {
            m_data=new char[1];
            *m_data='\0';
        }
        else//当初始化串存在的时候，为m_data申请同样大小的空间存放该串；
        {
            int length=strlen(str);
            m_data=new char[length+1];
            strcpy(m_data,str);
        }
    }

    String::String(const String &other)//拷贝构造函数，功能与构造函数类似。
    {
        int length=strlen(other.m_data);
        m_data=new [length+1];
        strcpy(m_data,other.m_data);
    }
    String& String::operator =(const String &other) 
    {
        if (this==&other)//当地址相同时，直接返回；
            return *this; 

        delete [] m_data;//当地址不相同时，删除原来申请的空间，重新开始构造；
        int length=sizeof(other.m_data);
        m_data=new [length+1];
        strcpy(m_data,other.m_data);
        return *this; 
    }

    String::ShowString()//由于m_data是私有成员，对象只能通过public成员函数来访问；
    {
        cout<<this->m_data<<endl;
    }

    main()
    {
        String AD;
        char * p="ABCDE";
        String B(p);
        AD.ShowString();
        AD=B;
        AD.ShowString();
    }
    ```



### 计算机网络

1. OSI七层模型？
    分层 | 作用 | 协议
    ---|---|---
    物理层 | 通过媒介传输比特，确定机械及电气规范（比特 Bit） | RJ45、CLOCK、IEEE802.3（中继器，集线器）
    数据链路层|将比特组装成帧和点到点的传递（帧 Frame）| PPP、FR、HDLC、VLAN、MAC（网桥，交换机）
    网络层|负责数据包从源到宿的传递和网际互连（包 Packet）|IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP（路由器）
    运输层|提供端到端的可靠报文传递和错误恢复（ 段Segment）|TCP、UDP、SPX
    会话层|建立、管理和终止会话（会话协议数据单元 SPDU）|NFS、SQL、NETBIOS、RPC
    表示层|对数据进行翻译、加密和压缩（表示协议数据单元 PPDU）|JPEG、MPEG、ASII
    应用层|允许访问OSI环境的手段（应用协议数据单元 APDU）|FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS

2. TCP/IP五层模型？


3. 网络序是大端还是小端？为什么要这样？
    大端，历史遗留问题

4. ping命令使用的是什么协议？
    ICMP协议  

5. 路由表一般包含什么？
6. 停止等待协议的缺点？为什么？
7. 拥塞控制的方式？具体怎么做的？快重传的时机是什么？
8.  DNS协议如何实现将域名解析为IP地址的？
9.  创建进程的步骤？
10. 进程切换发生的原因？处理进程切换的步骤？
11. TCP三次握手和四次挥手及各自的状态？
    【TCP 建立连接全过程解释】
    1. 客户端发送 SYN 给服务器，说明客户端请求建立连接；
    2. 服务端收到客户端发的 SYN，并回复 SYN+ACK 给客户端（同意建立连接）；
    3. 客户端收到服务端的 SYN+ACK 后，回复 ACK 给服务端（表示客户端收到了服务端发的同意报文）；
    4. 服务端收到客户端的 ACK，连接已建立，可以数据传输。

    TCP为什么要进行三次握手？  

    【答案一】因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而 UDP 则不需建立可靠传输，因此 UDP 不需要三次握手。）

    > [Google Groups . TCP 建立连接为什么是三次握手？{技术}{网络通信}](https://groups.google.com/forum/#!msg/pongba/kF6O7-MFxM0/5S7zIJ4yqKUJ)

    【答案二】因为双方都需要确认对方收到了自己发送的序列号，确认过程最少要进行三次通信。

    > [知乎 . TCP 为什么是三次握手，而不是两次或四次？](https://www.zhihu.com/question/24853633/answer/115173386)

    【答案三】为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。


    【TCP 释放连接全过程解释】

    1. 客户端发送 FIN 给服务器，说明客户端不必发送数据给服务器了（请求释放从客户端到服务器的连接）；
    2. 服务器接收到客户端发的 FIN，并回复 ACK 给客户端（同意释放从客户端到服务器的连接）；
    3. 客户端收到服务端回复的 ACK，此时从客户端到服务器的连接已释放（但服务端到客户端的连接还未释放，并且客户端还可以接收数据）；
    4. 服务端继续发送之前没发完的数据给客户端；
    5. 服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）；
    6. 客户端收到服务端的 FIN+ACK，并回复 ACK 给客户端（同意释放从服务端到客户端的连接）；
    7. 服务端收到客户端的 ACK 后，释放从服务端到客户端的连接。

12. TCP如果两次握手会出什么问题？那三次握手又会造成什么问题？有什么好的解决方法没？
    因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）。所以 TCP 释放连接时服务器的 ACK 和 FIN 是分开发送的（中间隔着数据传输），而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。

13. TCP四次挥手为什么要有TIME_WAIT状态？为什么？
    1. 为了保证客户端发送的最后一个 ACK 报文能够到达服务端。若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时。
    2. 防止已失效的连接请求报文段出现在本连接中。TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。

14. TCP和UDP区别
    **TCP是一种面向连接的、可靠的、字节流服务**
    14.1 面向链接：TCP面向链接，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须通过三次握手先建立一个TCP连接。在一个TCP中仅有两方彼此通信，多播和广播不能用于TCP。UDP是不可靠的传输，传输前不需要建立链接，可以应用多播和广播实现一对多的通信。
    14.2 可靠性：TCP提供端到端的流量控制，对收到的数据进行确认，采用超时重发，对失序的数据进行重新排序等机制保证数据通信的可靠性。而UDP是一种不可靠的服务，接收方可能不能收到发送方的数据报。
    14.3 TCP是一种流模式的协议，UDP是一种数据报模式的协议。进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。TCP应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。TCP会有粘包和半包的现象。
    14.4 效率上：速度上，一般TCP速度慢，传输过程中需要对数据进行确认，超时重发，还要对数据进行排序。UDP没有这些机制所以速度快。数据比例，TCP头至少20个字节，UDP头8个字节，相对效率高。组装效率上：TCP头至少20个字节，UDP头8个字节，系统组装上TCP相对慢。
    14.5 用途上：用于TCP可靠性，http，ftp使用。而由于UDP速度快，视频，在线游戏多用UDP，保证实时性。

    对于第三点的理解。TCP可能发送100个“包”，而接收到50个“包”，不是丢“包”了，而是每次接受的“包”都比发送的多，其实TCP并没有包的概念。例如，每次发10个字节，可能读得时候一次读了20个字节。TCP是一种流模式的协议，在接收到的缓存中按照发送的包得顺序自动按照顺序拼接好，因为数据基本来自同一个主机，而且是按照顺序发送过来的，TCP的缓存中存放的就是，连续的数据。感觉好像是多封装了一步比UDP。而UDP因为可能两个不同的主机，给同一个主机发送，（一个端口可能收到多个应用程序的数据），或者按照TCP那样合并数据，必然会造成数据错误。我觉得关键的原因还是，TCP是面向连接，而UDP是无连接的，这就导致，TCP接收的数据为一个主机发来且有序无误的，而UDP可能是多个主机发来的无序，可能错误的。  

